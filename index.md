---
layout: home
---

<div style="display: flex; justify-content: center; align-content: center;  flex-direction: column; align-items: center; text-align: center">
    <div style="border-radius: 50%; overflow: hidden; width: 35%;">
        <img src="assets/images/hwang headshot final.png"
            alt="Headshot of Alyssa Hwang">
    </div>
    <h2><a href="/fun">Alyssa Hwang</a></h2>
    <p>PhD Graduate</p>
    <a href="https://www.cis.upenn.edu/">Computer and Information Science</a>
    <a href="https://www.upenn.edu/">University of Pennsylvania</a>
    <p>she/her/hers <a href="https://namedrop.io/alyssahwang">üîà</a></p>
    <div>
        <a class="button lightbg" target="_blank" rel="noopener noreferrer" href="https://github.com/ahwang16">GitHub</a>
        <a class="button lightbg" target="_blank" rel="noopener noreferrer" href="https://scholar.google.com/citations?user=Tb-h12kAAAAJ&hl=en">Google Scholar</a>
        <a class="button lightbg" target="_blank" rel="noopener noreferrer" href="https://www.linkedin.com/in/alyssa-hwang/">LinkedIn</a>
        <a class="button lightbg" target="_blank" rel="noopener noreferrer" href="assets/files/Alyssa_Hwang_CV.pdf">CV</a>
        <a class="button lightbg" target="_blank" rel="noopener noreferrer" href="assets/files/Alyssa_Hwang_Resume.pdf">Resume</a>
    </div>
</div>

<h1>Welcome!</h1>

<div style="display: flex; justify-content: center; align-content: center; flex-direction: column;">
    <p>I graduated with my PhD in computer science from the University of Pennsylvania, where I was co-advised by <a href="https://boonloo.cis.upenn.edu/">Boon Thau Loo</a> and <a href="https://www.andrewhead.info">Andrew Head</a>. I studied <b>user interfaces for fine-grained integration of information</b>. I am broadly interested in designing AI-driven products that make complex information easier to understand. I enjoy thinking about many modalities, like reading tools or voice interaction. I am experienced with user research, LLM prototyping, and mixed-methods analysis.</p>
    <h2>I am on the job market!</h2>
    <p>
    I am seeking roles related to user experience research, HCI research, product management, AI strategy, or consulting. Feel free to look through my <a href="assets/files/Alyssa_Hwang_CV.pdf">CV</a>/<a href="assets/files/Alyssa_Hwang_Resume.pdf">resume</a> or send me an email if you would like to chat.
    </p>
    <h2>More about me</h2>
    <p>Beyond research, I was "chair emerita" of the <a href="https://penn-cisda.github.io">CIS Doctoral Association</a> and the founder of our department's Mentorship Program. I have interned at Google and AWS, and my work has been featured by Tech Crunch, the Associated Press, and over 100 other US news outlets. My first three years were supported by the <a href="https://www.nsfgrfp.org/">NSF Graduate Research Fellowship Program</a>. I received an MS in Computer and Information Studies from Penn while working on my PhD. I also hold a BS in Computer Science from Columbia University, where I conducted research at the Natural Language Text Processing Lab and wrote an undergraduate thesis with Professor <a href="http://www.cs.columbia.edu/~kathy/">Kathleen McKeown</a>.</p>
    
    <p>alyssahwang at alumni dot upenn dot edu</p>
</div>

<h1>Recent News</h1>

<div style="display: flex; justify-content: center; align-content: center; flex-direction: column;">
    <ul>
        <li>Dec 18, 2025: Officially graduated! Check out my <a href="/posts/projects/dissertation.html">dissertation and related projects</a>.</li>
        <li>Nov 26, 2025: I successfully defended my PhD dissertation!</li>
        <li>Aug 4, 2025: I defended my thesis proposal. Officially a PhD candidate! üë©üèª‚Äçüéì I am on the industry job market and expect to graduate in December.</li>
        <li>Oct 21, 2024: New collaborations, publications, and pre-prints! <a href="https://aclanthology.org/2024.acl-long.674/">RAID: A Shared Benchmark for Robust Evaluation of Machine-Generated Text Detectors</a> (ACL 2024), <a href="https://aclanthology.org/2024.acl-short.2/">FanOutQA: A Multi-Hop, Multi-Document Question Answering Benchmark for Large Language Models</a> (ACL 2024), <a href="https://arxiv.org/abs/2410.03882">JumpStarter: Getting Started on Personal Goals with AI-Powered Context Curation</a> (in submission), and <a href="https://arxiv.org/abs/2402.18479">NewsQs: Multi-Source Question Generation for the Inquiring Mind</a> (AWS 2022 internship paper).</li>
        <!-- <li>Mar 1, 2024: I'm on the cover of <a href="https://issuu.com/kentplace/docs/kentplace_w24_issue_pages_webquality">Kent Place Magazine</a>. üòÖ Go dragons!</li> -->
        <!-- <li>Feb 5, 2024: Looking forward to speaking at Women in Data Science @ Penn, Google, and Columbia in the next couple of months.</li> -->
        <!-- <li>Dec 1, 2023: I will be in Singapore for <a href="https://2023.emnlp.org/">EMNLP</a> next week. Looking forward to meeting new people and presenting <a href="https://github.com/zhudotexe/kani">Kani</a> at the open-source software <a href="https://nlposs.github.io/2023/">workshop</a> on Dec. 6 and attending the Salesforce networking dinner on Dec. 8!</li> -->
        <!-- <li>Nov 16, 2023: My work on GPT-Vision has been featured by <a href="https://techcrunch.com/2023/11/06/openai-gpt-4-with-vision-release-research-flaws/">TechCrunch</a>, <a href="https://apnews.com/article/chatgpt-openai-tech-showcase-da850be425aaa269e2915e9e0b1c726a">Associated Press</a>, <a href="https://penntoday.upenn.edu/news/peek-future-visual-data-interpretation">Penn Today</a>, and several other news outlets.</li> -->
        <!-- <li>Nov 6, 2023: I'm in San Francisco for <a href="https://devday.openai.com/">OpenAI DevDay 2023</a>! Feel free to come chat with me about GPT-Vision, voice assistants, NLPxHCI/Human-AI Interaction, qualitative analysis, and more.</li> -->
        <!-- <li>Nov 3, 2023: I just released <a href="https://arxiv.org/abs/2311.02069">Grounded Intuition of GPT-Vision's Abilities with Scientific Figures</a>, an in-depth analysis of alt text generation with GPT-Vision. I based my procedure on methods from social science and HCI. You can also find the data in this <a href="https://github.com/ahwang16/grounded-intuition-gpt-vision">repository</a>.</li> -->
        <!-- <li>Oct 9, 2023: Kani, a framework for building language model applications developed with <a href="https://zhu.codes/">Andrew Zhu</a> and <a href="https://liamdugan.com/">Liam Dugan</a>, has been accepted to the EMNLP Workshop of Natural Language Processing Open-Source Software (NLP-OSS). Our <a href="https://github.com/zhudotexe/kani">GitHub</a> also has over 480 stars.</li> -->
        <!-- <li>Oct 2, 2023: My work on Rewriting the Script is being featured on <a href="https://blog.seas.upenn.edu/rewriting-the-script-developing-effective-ai-assistants/">Penn Engineering Today</a>.</li> -->
        <!-- <li>Sept 29, 2023: I was invited to <a href="https://devday.openai.com/">OpenAI DevDay 2023</a>! Feel free to email or chat with me if you are also attending.</li> -->
        <!-- <li>Sept 25, 2023: Kani, our new framework for building language model applications, has over 400 stars on <a href="https://github.com/zhudotexe/kani">GitHub</a>, is trending on GitHub and Papers With Code, and has been featured in several news articles. Check out our <a href="https://arxiv.org/abs/2309.05542">preprint on arXiv</a>.</li> -->
    </ul>
</div>
